{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Views look like this in their simplified string notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{P(a())Q(b())R(c())}^{0}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{P(a())Q(b())R(c())}^{0}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of operating on `View` objects directly, let's consider whether certain mutation\n",
    "operations could be done on the string representations with less overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P(a())Q(b())R(c())'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage = \"{P(a())Q(b())R(c())}^{0}\".split(\"}^{\")[0][1:]\n",
    "stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{P(a)Q(b)R(c)}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyetr import View\n",
    "v = View.from_str(\"{P(a())Q(b())R(c())}^{0}\")\n",
    "str(v.stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[P(a), Q(b), R(c)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(v.stage)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I don't think it'll be pure string parsing. But, we can disassemble and reassemble\n",
    "views using their `.stage` and `.supposition` attributes, then add in or mutate the\n",
    "decomposed string representations before adding any new information (predicates or\n",
    "quantifiers) _as strings_—much simpler than actually constructing `PredicateAtom`s or\n",
    "others from scratch.\n",
    "\n",
    "_NOTE_: taking this back. When you print `.stage` you for some reason lose the\n",
    "parentheses identifying constants as constants and not arbitrary. So, I think we're just\n",
    "going to split on `}^{`. Or, maybe more versatile, we'll just process with\n",
    "`[:-1] + \"())\"` whenever we print stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'Q', 'R']\n",
      "['a', 'b', 'c']\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.findall(\"[A-Z]\", str(v.atoms)))\n",
    "print(re.findall(\"[a-z]\", str(v.atoms)))\n",
    "max_object = max(re.findall(\"[a-z]\", str(v.atoms)))\n",
    "\n",
    "print(chr(ord(max_object) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2638085100.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    str(list(v.stage)[0]) +\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "str(list(v.stage)[0]) + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_to_str(atom) -> str:\n",
    "    return str(atom)[:-1] + \"())\"\n",
    "\n",
    "def state_to_str(state) -> str:\n",
    "    return \"\".join([atom_to_str(a) for a in state])\n",
    "\n",
    "def set_of_states_to_str(set_of_states) -> str:\n",
    "    return \"{\" + \",\".join([state_to_str(s) for s in set_of_states]) + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P(a())', 'Q(b())', 'R(c())']\n",
      "{P(a), Q(b), R(c)}\n",
      "{P(a())Q(b())R(c())}\n",
      "{P(a())Q(b())R(c())}\n"
     ]
    }
   ],
   "source": [
    "print([atom_to_str(a) for a in v.atoms])\n",
    "print(v.atoms)\n",
    "print(set_of_states_to_str(v.stage))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "from pyetr import ArbitraryObject, FunctionalTerm, PredicateAtom\n",
    "\n",
    "def get_object_sets_for_view(\n",
    "    view: View\n",
    ") -> tuple[dict[str, set[str]], set[str], set[str]]:\n",
    "    \"\"\"Take a view and return sets of predicates (at different arities), constants, and\n",
    "        arbitrary objects used in the view.\n",
    "\n",
    "    Args:\n",
    "        view (View): The View to parse.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If we ever handle a FunctionalTerm with a nonzero arity.\n",
    "        ValueError: If we ever handle a term that's neither an ArbitraryObject nor a\n",
    "            Functional Term\n",
    "\n",
    "    Returns:\n",
    "        tuple[dict[str, set[str]], set[str], set[str]]:\n",
    "            dict[str, set[str]]: Predicates, mapping arity to a set of letters\n",
    "            set[str]: Constants\n",
    "            set[str]: Arbitrary objects\n",
    "    \"\"\"\n",
    "    predicates: dict[str, set[str]] = {}\n",
    "    constants: set[str] = set()\n",
    "    arb_objs: set[str] = set()\n",
    "\n",
    "    for state in view.weights._weights.keys():\n",
    "        for atom in state:\n",
    "            atom = cast(PredicateAtom, atom)\n",
    "            arity = str(atom.predicate.arity)\n",
    "            name = str(atom.predicate.name)\n",
    "            if arity not in predicates.keys():\n",
    "                predicates[arity] = set([name])\n",
    "            else:\n",
    "                predicates[arity].add(name)\n",
    "\n",
    "            for term in atom.terms:\n",
    "                if type(term) == ArbitraryObject: arb_objs.add(term.name)\n",
    "                elif type(term) == FunctionalTerm:\n",
    "                    if term.f.arity != 0: raise ValueError\n",
    "                    constants.add(term.f.name)\n",
    "                else: raise ValueError\n",
    "\n",
    "    return predicates, constants, arb_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{{A(a()),A(b())},\n",
       " {A(a()),A(b()*)},\n",
       " {A(a()),B(a())},\n",
       " {A(a()),B(a()*)},\n",
       " {A(a()),B(b())},\n",
       " {A(a()),B(b()*)},\n",
       " {A(a()),~A(a())},\n",
       " {A(a()),~A(a()*)},\n",
       " {A(a()),~A(b())},\n",
       " {A(a()),~A(b()*)},\n",
       " {A(a()),~B(a())},\n",
       " {A(a()),~B(a()*)},\n",
       " {A(a()),~B(b())},\n",
       " {A(a()),~B(b()*)},\n",
       " {A(a())B(a())},\n",
       " {A(a())B(a()*)},\n",
       " {A(a())},\n",
       " {A(a()*)},\n",
       " {A(b())A(a())},\n",
       " {A(b()*)A(a())},\n",
       " {B(b())A(a())},\n",
       " {B(b()*)A(a())},\n",
       " {~A(a())A(a())},\n",
       " {~A(a()*)A(a())},\n",
       " {~A(b())A(a())},\n",
       " {~A(b()*)A(a())},\n",
       " {~B(a())A(a())},\n",
       " {~B(a()*)A(a())},\n",
       " {~B(b())A(a())},\n",
       " {~B(b()*)A(a())},\n",
       " ∀a ∀b {A(a)A(b)},\n",
       " ∀a ∀b {A(a)A(b*)},\n",
       " ∃b ∀a {A(a)A(b)},\n",
       " ∃b ∀a {A(a)A(b*)}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_view_mutations(view: View) -> set[View]:\n",
    "    mutations = set()\n",
    "\n",
    "    # Assemble lists of strings of predicates, constants, and arbitrary objects\n",
    "    predicates, constants, arb_objs = get_object_sets_for_view(view)\n",
    "\n",
    "    if len(predicates.keys()) > 1: raise ValueError\n",
    "    predicates = predicates[\"1\"]  # For now we only do unary predicates\n",
    "\n",
    "    max_predicate = max(predicates)\n",
    "    new_predicate = chr(ord(max_predicate) + 1)\n",
    "\n",
    "    if len(arb_objs) == 0:\n",
    "        arb_objs = set([\"a\"])\n",
    "        new_arb_obj = \"a\"\n",
    "    else:\n",
    "        max_arb_obj = max(arb_objs)\n",
    "        new_arb_obj = chr(ord(max_arb_obj) + 1)\n",
    "\n",
    "    for o in constants:\n",
    "        # Also append problems where the variable is taken to be at issue in all\n",
    "        # occurrences (can I do this with issue only occurring sometimes?)\n",
    "        for is_at_issue in [new_arb_obj, new_arb_obj + \"*\"]:\n",
    "            mutations.add(\n",
    "                View.from_str(\n",
    "                    f\"A{new_arb_obj} \" + view.to_str().replace(o + \"()\", is_at_issue)\n",
    "                )\n",
    "            )\n",
    "            mutations.add(\n",
    "                View.from_str(\n",
    "                    f\"E{new_arb_obj} \" + view.to_str().replace(o + \"()\", is_at_issue)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if len(constants) == 0:\n",
    "        constants = set([\"a\"])\n",
    "        new_constant = \"a\"\n",
    "    else:\n",
    "        max_constant = max(constants)\n",
    "        new_constant = chr(ord(max_constant) + 1)\n",
    "\n",
    "    predicates.add(new_predicate)\n",
    "    constants.add(new_constant)\n",
    "\n",
    "    atoms = [atom_to_str(a) for a in view.atoms] + [f\"{p}({o}())\" for p in predicates for o in constants]\n",
    "\n",
    "    # We also don't do anything with suppositions in this version\n",
    "    # TODO: prepend all possible quantifier strings given the current set of arbitrary\n",
    "    # objects\n",
    "    for atom in atoms:\n",
    "        atom_at_issue = atom[:-1] + \"*)\"\n",
    "        # All conjunctions\n",
    "        for i in range(len(list(view.stage))):\n",
    "            new_state_str = state_to_str(list(view.stage)[i]) + atom\n",
    "            new_stage_str = \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage])[:i] +\n",
    "                [new_state_str] +\n",
    "                list([state_to_str(s) for s in view.stage])[i+1:]\n",
    "            ) + \"}\"\n",
    "            mutations.add(View.from_str(new_stage_str))\n",
    "\n",
    "            # Also add one where the new atom is at issue\n",
    "            new_state_str = state_to_str(list(view.stage)[i]) + atom_at_issue\n",
    "            new_stage_str = \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage])[:i] +\n",
    "                [new_state_str] +\n",
    "                list([state_to_str(s) for s in view.stage])[i+1:]\n",
    "            ) + \"}\"\n",
    "            mutations.add(View.from_str(new_stage_str))\n",
    "        \n",
    "        # Disjunctions\n",
    "        mutations.add(\n",
    "            View.from_str(\n",
    "                \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage]) +\n",
    "                [atom]\n",
    "            ) + \"}\"\n",
    "            )\n",
    "        )\n",
    "        mutations.add(\n",
    "            View.from_str(\n",
    "                \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage]) +\n",
    "                [atom_at_issue]\n",
    "            ) + \"}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Now, negate\n",
    "        if atom[0] == \"~\": atom = atom[1:]\n",
    "        else: atom = \"~\" + atom\n",
    "\n",
    "        atom_at_issue = atom[:-1] + \"*)\"\n",
    "        # All conjunctions\n",
    "        for i in range(len(list(view.stage))):\n",
    "            new_state_str = state_to_str(list(view.stage)[i]) + atom\n",
    "            new_stage_str = \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage])[:i] +\n",
    "                [new_state_str] +\n",
    "                list([state_to_str(s) for s in view.stage])[i+1:]\n",
    "            ) + \"}\"\n",
    "            mutations.add(View.from_str(new_stage_str))\n",
    "\n",
    "            # Also add one where the new atom is at issue\n",
    "            new_state_str = state_to_str(list(view.stage)[i]) + atom_at_issue\n",
    "            new_stage_str = \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage])[:i] +\n",
    "                [new_state_str] +\n",
    "                list([state_to_str(s) for s in view.stage])[i+1:]\n",
    "            ) + \"}\"\n",
    "            mutations.add(View.from_str(new_stage_str))\n",
    "        \n",
    "        # Disjunctions\n",
    "        mutations.add(\n",
    "            View.from_str(\n",
    "                \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage]) +\n",
    "                [atom]\n",
    "            ) + \"}\"\n",
    "            )\n",
    "        )\n",
    "        mutations.add(\n",
    "            View.from_str(\n",
    "                \"{\" + \",\".join(\n",
    "                list([state_to_str(s) for s in view.stage]) +\n",
    "                [atom_at_issue]\n",
    "            ) + \"}\"\n",
    "            )\n",
    "        )        \n",
    "\n",
    "    return mutations\n",
    "\n",
    "get_view_mutations(View.from_str(\"∀a {A(a)A(a())}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problem_mutations(problem: tuple[View, ...]) -> set[tuple[View, ...]]:\n",
    "    mutations = set()\n",
    "    for i, view in enumerate(problem):\n",
    "        for mut in get_view_mutations(view):\n",
    "            mutations.add(\n",
    "                problem[:i] + (mut,) + problem[i+1:]\n",
    "            )\n",
    "    mutations.add(problem + (View.from_str(\"{A(a())}\"),))\n",
    "    return mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with minimum 2 premises\n",
    "reasoning_problems: set[tuple[View, ...]] = set([(\n",
    "    View.from_str(\"{A(a())}\"),\n",
    "    View.from_str(\"{A(a())}\"),\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "77\n",
      "157\n",
      "340\n",
      "522\n",
      "603\n",
      "705\n",
      "887\n",
      "1064\n",
      "1263\n",
      "1353\n",
      "1427\n",
      "1522\n",
      "1657\n",
      "1880\n",
      "2043\n"
     ]
    }
   ],
   "source": [
    "from etr_case_generator.ontology import ELEMENTS\n",
    "from pyetr.inference import default_inference_procedure\n",
    "from etr_case_generator.view_to_natural_language import view_to_natural_language\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from etr_case_generator.generator import ETRCaseGenerator\n",
    "from etr_case_generator.reasoning_problem import ReasoningProblem\n",
    "\n",
    "\n",
    "while len(reasoning_problems) > 0 and len(reasoning_problems) < 2000:\n",
    "    problem = reasoning_problems.pop()\n",
    "\n",
    "    # Format current problem as a ReasoningProblem and write it out\n",
    "    # r = ReasoningProblem(generator=ETRCaseGenerator(ELEMENTS))\n",
    "    # r.update_premises(list(problem[:-1]))\n",
    "    # r.update_query(problem[-1])\n",
    "    # d = r.to_dict()\n",
    "    # print(d[\"full_prose\"])\n",
    "    # print()\n",
    "    # print(f\"etr_conclusion: {d['etr_conclusion']}\")\n",
    "    # print(f\"etr_conclusion_is_categorical: {d['etr_conclusion_is_categorical']}\")\n",
    "\n",
    "    for mut in get_problem_mutations(problem):\n",
    "        # Check if the conclusion is verum, and if so, skip this mutation\n",
    "        r = ReasoningProblem(ontology=ELEMENTS)\n",
    "        r.update_premises(list(mut))\n",
    "        skip = False\n",
    "        if r.etr_conclusion[0].is_verum:\n",
    "            skip = True\n",
    "\n",
    "        # If the ETR conclusion is identical to one of the premises, this problem\n",
    "        # is not interesting\n",
    "        for premise in r.premises:\n",
    "            if premise[0] == r.etr_conclusion[0]:\n",
    "                skip = True\n",
    "\n",
    "        # If the ETR conclusion contains verum/falsum, skip\n",
    "        for state in r.etr_conclusion[0].stage:\n",
    "            if len(state) == 0: skip = True\n",
    "\n",
    "        if not skip: reasoning_problems.add(mut)\n",
    "\n",
    "    print(len(reasoning_problems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(reasoning_problems)[76]\n",
    "\n",
    "r = ReasoningProblem(ontology=ELEMENTS)\n",
    "r.update_premises(list(p[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.premises[0][0] == r.premises[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for state in r.etr_conclusion[0].stage: print(len(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('for all B, for all A, B is gaseous under high pressure and A is gaseous under high pressure',\n",
       " {'A': 'gaseous under high pressure'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_to_natural_language(ELEMENTS, View.from_str(\"∀b ∀a {A(b*)A(a)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reasoning_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb73b476f7fe48f1825064f9d043b30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open(f\"datasets/4_asdf.jsonl\", \"w\") as f:\n",
    "    for problem in tqdm(reasoning_problems):\n",
    "        r = ReasoningProblem(ontology=ELEMENTS)\n",
    "        r.update_premises(list(problem))\n",
    "        f.write(json.dumps(r.to_dict()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<View\n",
      "  stage={{<PredicateAtom predicate=<Predicate name=A arity=1> terms=(<FunctionalTerm f=Function(x, 0) t=()>)>},{<PredicateAtom predicate=<Predicate name=A arity=1> terms=(<ArbitraryObject name=x>)>}}\n",
      "  supposition={{}}\n",
      "  dep_rel=<DependencyRelation deps=[] unis=frozenset() exis=frozenset({x})>\n",
      "  issue_structure={}\n",
      "  weights=<Weights {<PredicateAtom predicate=<Predicate name=A arity=1> terms=(<ArbitraryObject name=x>)>}: <Weight multi=<Multiset items=[]> add=<Multiset items=[]>>,{<PredicateAtom predicate=<Predicate name=A arity=1> terms=(<FunctionalTerm f=Function(x, 0) t=()>)>}: <Weight multi=<Multiset items=[]> add=<Multiset items=[]>>>\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(View.from_str(\"∃x {A(x),A(x())}\").detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ArbitraryObject name=x>\n",
      "<ArbitraryObject name=x>\n",
      "<FunctionalTerm f=Function(x, 0) t=()>\n"
     ]
    }
   ],
   "source": [
    "for k in View.from_str(\"∃x {A(x)B(x),A(x())}\").weights._weights.keys():\n",
    "    for a in k:\n",
    "        print(a.terms[0].detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{A(a())}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_inference_procedure([View.from_str(\"Ax {A(x)}^{B(x*)}\"), View.from_str(\"{B(a()*)}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{B(a()*)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "View.from_str(\"{B(a())B(a()*)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', 'R', 'Q']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"[A-Z]\", v.to_str())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble lists of strings of predicates, constants, and arbitrary objects\n",
    "predicates: dict[str, set[str]] = {}\n",
    "constants: set[str] = set()\n",
    "arb_objs: set[str] = set()\n",
    "\n",
    "for state in View.from_str(\"∃x {A(x)B(x),A(x())}\").weights._weights.keys():\n",
    "    for atom in state:\n",
    "        atom = cast(PredicateAtom, atom)\n",
    "        arity = str(atom.predicate.arity)\n",
    "        name = str(atom.predicate.name)\n",
    "        if arity not in predicates.keys():\n",
    "            predicates[arity] = set([name])\n",
    "        else:\n",
    "            predicates[arity].add(name)\n",
    "\n",
    "        for term in atom.terms:\n",
    "            if type(term) == ArbitraryObject: arb_objs.add(term.name)\n",
    "            elif type(term) == FunctionalTerm:\n",
    "                if term.f.arity != 0: raise ValueError\n",
    "                constants.add(term.f.name)\n",
    "            else: raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
