Copied /home/keenan/Dev/etr_case_generator/datasets/fully_balanced_open_ended.jsonl to datasets/etr_for_lm_eval.jsonl
Configuration:
  Model Class: openai-chat-completions
  Model: gpt-3.5-turbo-0125
  Evaluation harness path: /home/keenan/Dev/lm-evaluation-harness/
  Include path: /home/keenan/Dev/etr_case_generator/
  Task: etr_problems_open_ended

2025-01-31:12:34:33,178 WARNING  [openai_completions.py:108] chat-completions endpoint requires the `--apply_chat_template` flag.
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 360 examples [00:00, 12917.36 examples/s]
2025-01-31:12:34:34,197 WARNING  [evaluator.py:270] Overwriting default num_fewshot of etr_problems_open_ended from None to 0
2025-01-31:12:34:34,197 WARNING  [evaluator.py:406] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
  0%|          | 0/360 [00:00<?, ?it/s]100%|██████████| 360/360 [00:00<00:00, 4135.09it/s]
Requesting API:   0%|          | 0/360 [00:00<?, ?it/s]2025-01-31:12:34:34,466 WARNING  [api_models.py:287] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-01-31:12:34:36,064 WARNING  [api_models.py:374] API request failed with error message: {
  "error": {
    "message": "max_tokens is too large: 10000. This model supports at most 4096 completion tokens, whereas you provided 10000.",
    "type": "invalid_request_error",
    "param": "max_tokens",
    "code": null
  }
}. Retrying...
2025-01-31:12:34:37,917 WARNING  [api_models.py:374] API request failed with error message: {
  "error": {
    "message": "max_tokens is too large: 10000. This model supports at most 4096 completion tokens, whereas you provided 10000.",
    "type": "invalid_request_error",
    "param": "max_tokens",
    "code": null
  }
}. Retrying...
2025-01-31:12:34:39,680 WARNING  [api_models.py:374] API request failed with error message: {
  "error": {
    "message": "max_tokens is too large: 10000. This model supports at most 4096 completion tokens, whereas you provided 10000.",
    "type": "invalid_request_error",
    "param": "max_tokens",
    "code": null
  }
}. Retrying...
Traceback (most recent call last):
  File "/home/keenan/.local/bin/lm_eval", line 8, in <module>
    sys.exit(cli_evaluate())
             ^^^^^^^^^^^^^^
  File "/home/keenan/Dev/lm-evaluation-harness/lm_eval/__main__.py", line 382, in cli_evaluate
    results = evaluator.simple_evaluate(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/Dev/lm-evaluation-harness/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/Dev/lm-evaluation-harness/lm_eval/evaluator.py", line 303, in simple_evaluate
    results = evaluate(
              ^^^^^^^^^
  File "/home/keenan/Dev/lm-evaluation-harness/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/Dev/lm-evaluation-harness/lm_eval/evaluator.py", line 507, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/Dev/lm-evaluation-harness/lm_eval/models/api_models.py", line 598, in generate_until
    outputs = retry(
              ^^^^^^
  File "/home/keenan/.local/pipx/venvs/lm-eval/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/.local/pipx/venvs/lm-eval/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/.local/pipx/venvs/lm-eval/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/.local/pipx/venvs/lm-eval/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/.local/pipx/venvs/lm-eval/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/keenan/.local/pipx/venvs/lm-eval/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/keenan/Dev/lm-evaluation-harness/lm_eval/models/api_models.py", line 377, in model_call
    response.raise_for_status()
  File "/home/keenan/.local/pipx/venvs/lm-eval/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.openai.com/v1/chat/completions
Requesting API:   0%|          | 0/360 [00:05<?, ?it/s]
